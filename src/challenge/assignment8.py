# BLUEPRINT | DONT EDIT

import requests
from bs4 import BeautifulSoup

response = requests.get(
    "https://berlinstartupjobs.com/engineering/",
    headers={
        "User-Agent":
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    })

skills = ["python", "typescript", "javascript", "rust"]

# /BLUEPRINT

# ğŸ‘‡ğŸ» YOUR CODE ğŸ‘‡ğŸ»:

'''
https://berlinstartupjobs.com/engineering/
https://berlinstartupjobs.com/skill-areas/python/
https://berlinstartupjobs.com/skill-areas/typescript/
https://berlinstartupjobs.com/skill-areas/javascript/
ì²« ë²ˆì§¸ URLì—ëŠ” í˜ì´ì§€ê°€ ìˆìœ¼ë¯€ë¡œ pagination ì„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
ë‚˜ë¨¸ì§€ URLì€ íŠ¹ì • ìŠ¤í‚¬ì— ëŒ€í•œ ê²ƒì…ë‹ˆë‹¤. URLì˜ êµ¬ì¡°ì— ìŠ¤í‚¬ ì´ë¦„ì´ ìˆìœ¼ë¯€ë¡œ ëª¨ë“  ìŠ¤í‚¬ì„ ìŠ¤í¬ë˜í•‘í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë˜í¼ë¥¼ ë§Œë“œì„¸ìš”.
íšŒì‚¬ ì´ë¦„, ì§ë¬´ ì œëª©, ì„¤ëª… ë° ì§ë¬´ ë§í¬ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
'''

# 0. ë³€ìˆ˜ ë° ìƒìˆ˜ ì„ ì–¸
BASE_URL = "https://berlinstartupjobs.com"
results = {}

# 1. í•¨ìˆ˜ ì„ ì–¸
def scrape_page(sub_url, page=None, skill=None):
    result = []
    
    url = f"{BASE_URL}/{sub_url}"
    if page is not None:
        url = f"{url}/page/{page}"
    if skill is not None:
        url = f"{url}/{skill}"
    response = requests.get(
        url,
        headers={
            "User-Agent":
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
    )
    
    soup = BeautifulSoup(response.content, "html.parser")
    jobs = soup.find("ul", class_="jobs-list-items").find_all("li", class_="bjs-jlid")
    for job in jobs:
        company_name = job.find("a", class_="bjs-jlid__b").text
        job_title = job.find("h4", class_="bjs-jlid__h").find("a").text
        job_description = job.find("div", class_="bjs-jlid__description").text
        job_link = job.find("h4", class_="bjs-jlid__h").find("a")["href"]
        result.append({
            "company_name": company_name,
            "job_title": job_title,
            "job_description": job_description,
            "job_link": job_link
        })
        
    return result

# 2. ì—”ì§€ë‹ˆì–´ë§ URL í˜ì´ì§€ í™•ì¸
soup = BeautifulSoup(response.content, "html.parser")
buttons = soup.find("ul", class_="bsj-nav").find_all("a", class_="page-numbers")
total_pages = int(buttons[-2].text)

# 2-1. ì—”ì§€ë‹ˆì–´ë§ URL ìŠ¤í¬ë˜í•‘
engineering_results = []
for page in range(1, total_pages + 1):
    engineering_result = scrape_page(sub_url="engineering", page=page)
    engineering_results.append(engineering_result)

results['engineering'] = engineering_results

# 3. ìŠ¤í‚¬ URL ìŠ¤í¬ë˜í•‘
for skill in skills:
    skill_result = scrape_page(sub_url="skill-areas", skill=skill)
    results[skill] = skill_result

# 4. ì¶œë ¥
for key, values in results.items():
    print(f"{key}:\n")
    print(values)
    print("-"*50)
    
# /YOUR CODE